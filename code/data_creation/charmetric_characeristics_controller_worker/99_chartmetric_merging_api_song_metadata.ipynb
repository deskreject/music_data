{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t# Author: Alexander Staub\n",
    "\t## Last changed: 2025.06.23\n",
    "\t## Purpose: Using the chartmetric IDs to get song level metadata post spotify data collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing packages\n",
    "import time\n",
    "import requests\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Cell 1: Configuration ---\n",
    "\n",
    "NUM_WORKERS = 3  # Must match the number of workers you ran\n",
    "# --- This should point to the directory containing your \"part_1\", \"part_2\", etc. folders ---\n",
    "METADATA_OUTPUT_DIR = \"//bigdata.wu.ac.at/delpero/Data_alexander/data/raw_data/chartmetric/chartmetric_chars/\"\n",
    "# --- This is the path for your final, combined output file. ---\n",
    "FINAL_OUTPUT_FILE = \"//bigdata.wu.ac.at/delpero/Data_alexander/data/raw_data/chartmetric/chartmetric_chars/complete_charmetric_chars.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to merge results from all workers...\n",
      "Loading //bigdata.wu.ac.at/delpero/Data_alexander/data/raw_data/chartmetric/chartmetric_chars/part_1\\song_chars_checkpoint.json...\n",
      "Loading //bigdata.wu.ac.at/delpero/Data_alexander/data/raw_data/chartmetric/chartmetric_chars/part_2\\song_chars_checkpoint.json...\n",
      "Loading //bigdata.wu.ac.at/delpero/Data_alexander/data/raw_data/chartmetric/chartmetric_chars/part_3\\song_chars_checkpoint.json...\n",
      "\n",
      "Successfully merged a total of 4573 responses.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Combine Worker Results ---\n",
    "all_responses = []\n",
    "print(\"Starting to merge results from all workers...\")\n",
    "\n",
    "for i in range(NUM_WORKERS):\n",
    "    part_number = i + 1\n",
    "    # --- The path is dynamically constructed to find each worker's checkpoint file. ---\n",
    "    file_path = os.path.join(METADATA_OUTPUT_DIR, f\"part_{part_number}\", \"song_chars_checkpoint.json\")\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading {file_path}...\")\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            # Use extend to add all items from the loaded list to the master list\n",
    "            all_responses.extend(data)\n",
    "    else:\n",
    "        print(f\"WARNING: Could not find result file for worker {part_number} at {file_path}\")\n",
    "\n",
    "print(f\"\\nSuccessfully merged a total of {len(all_responses)} responses.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract necessary information from the search output\n",
    "def extract_song_info(search_output):\n",
    "    # Extract the main object\n",
    "    obj = search_output.get('obj', {})\n",
    "    \n",
    "    # Artist: take first artist if available\n",
    "    if obj.get('artists') and len(obj['artists']) > 0:\n",
    "        artist = obj['artists'][0]\n",
    "        artist_id = artist.get('id', None)\n",
    "        artist_name = artist.get('name', None)\n",
    "        artist_label = artist.get('label', None)\n",
    "        artist_booking_agent = artist.get('booking_agent', None)\n",
    "        artist_general_manager = artist.get('general_manager', None)\n",
    "    else:\n",
    "        artist_id = artist_name = artist_label = artist_booking_agent = artist_general_manager = None\n",
    "\n",
    "    # Albums: select the album with the earliest release date\n",
    "    if obj.get('albums') and len(obj['albums']) > 0:\n",
    "        def parse_date(album):\n",
    "            try:\n",
    "                return datetime.strptime(album.get('release_date', ''), '%Y-%m-%d')\n",
    "            except Exception:\n",
    "                return datetime.max\n",
    "        sorted_albums = sorted(obj['albums'], key=parse_date)\n",
    "        earliest_album = sorted_albums[0]\n",
    "        album_id = earliest_album.get('id', None)\n",
    "        album_name = earliest_album.get('name', None)\n",
    "        album_release_date = earliest_album.get('release_date', None)\n",
    "        album_label = earliest_album.get('label', None)\n",
    "    else:\n",
    "        album_id = album_name = album_release_date = album_label = None\n",
    "\n",
    "    # Use a pipe '|' as delimiter for multiple values\n",
    "    delimiter = '|'\n",
    "    \n",
    "    # Moods: concatenate mood names\n",
    "    if obj.get('moods') and len(obj['moods']) > 0:\n",
    "        moods = delimiter.join([m.get('name', '') for m in obj['moods']])\n",
    "    else:\n",
    "        moods = None\n",
    "    \n",
    "    # Activities: concatenate activity names\n",
    "    if obj.get('activities') and len(obj['activities']) > 0:\n",
    "        activities = delimiter.join([a.get('name', '') for a in obj['activities']])\n",
    "    else:\n",
    "        activities = None\n",
    "    \n",
    "    # Songwriters: concatenate songwriter names\n",
    "    if obj.get('songwriters') and len(obj['songwriters']) > 0:\n",
    "        songwriters = delimiter.join(obj['songwriters'])\n",
    "    else:\n",
    "        songwriters = None\n",
    "    \n",
    "    # songwriterIds is not present in the example so we assign None\n",
    "    songwriterIds = None\n",
    "\n",
    "    # Create a one-row DataFrame with the desired columns\n",
    "    data = {\n",
    "        'chartmetric_ids': obj.get('id', None),\n",
    "        'Name': obj.get('name', None),\n",
    "        'Composer_name': obj.get('composer_name', None),\n",
    "        'Artist_id': artist_id,\n",
    "        'Artist_name': artist_name,\n",
    "        'Artist_label': artist_label,\n",
    "        'Artist_booking_agent': artist_booking_agent,\n",
    "        'Artist_general_manager': artist_general_manager,\n",
    "        'Albums_id': album_id,\n",
    "        'Albums_name': album_name,\n",
    "        'Albums_release_date': album_release_date,\n",
    "        'Albums_label': album_label,\n",
    "        'Tags': obj.get('tags', None),\n",
    "        'Moods': moods,\n",
    "        'Activities': activities,\n",
    "        'Songwriters': songwriters,\n",
    "        'songwriterIds': songwriterIds,\n",
    "        'Tempo': obj.get('tempo', None),\n",
    "        'Duration_ms': obj.get('duration_ms', None)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing all responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5268\\2132265931.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_extracted_df = pd.concat(extracted_rows, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed data into a DataFrame with 4573 rows.\n",
      "Final merged and processed data saved to: //bigdata.wu.ac.at/delpero/Data_alexander/data/raw_data/chartmetric/chartmetric_chars/complete_charmetric_chars.json\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Parse All Responses and Create Final DataFrame ---\n",
    "\n",
    "print(\"Parsing all responses...\")\n",
    "extracted_rows = []\n",
    "for resp in all_responses:\n",
    "    # Filter out any None values that resulted from API errors\n",
    "    if resp is not None:\n",
    "        extracted_df = extract_song_info(resp)\n",
    "        extracted_rows.append(extracted_df)\n",
    "\n",
    "if extracted_rows:\n",
    "    final_extracted_df = pd.concat(extracted_rows, ignore_index=True)\n",
    "    print(f\"Successfully parsed data into a DataFrame with {len(final_extracted_df)} rows.\")\n",
    "    \n",
    "    # Save the final, clean data\n",
    "    final_extracted_df.to_json(FINAL_OUTPUT_FILE, orient=\"records\", lines=True)\n",
    "    print(f\"Final merged and processed data saved to: {FINAL_OUTPUT_FILE}\")\n",
    "else:\n",
    "    print(\"No data was extracted. Final file not saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chartmetric_ids_spotify data as a dataframe\n",
    "chartmetric_ids_spotify = pd.read_csv(\n",
    "    \"//bigdata.wu.ac.at/delpero/Data_alexander/data/raw_data/chartmetric/chartmetric_ids/chartmetric_ids_sample.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Join the Extracted Data to the Original DataFrame ---\n",
    "# It is assumed that the 'id' column in song_chars_extracted matches the 'id' column in spotify_sample.\n",
    "merged_song_chars = chartmetric_ids_spotify.merge(final_extracted_df, on=\"chartmetric_ids\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#safe the final dataframe\n",
    "# Save as JSON (records-oriented with one JSON object per line)\n",
    "\n",
    "#sample dataset\n",
    "merged_song_chars.to_json(\"Z:/Data_alexander/data/raw_data/chartmetric/chartmetric_chars/sample_charmetric_chars.json\", orient=\"records\", lines=True)\n",
    "\n",
    "#the songs + artist 1980-2000 dataset\n",
    "# merged_song_chars.to_json(\"//bigdata.wu.ac.at/delpero/Data_alexander/data/incidental/chartmetric/chartmetric_metadata/all_1980_2000_charmetric_chars.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code used to derive an example and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Retrieve song characteristics from Chartmetric ID ---\n",
    "def get_songchars_ids(chartmetric_id):\n",
    "    endpoint = f\"/api/track/{chartmetric_id}\"\n",
    "    try:\n",
    "        response = get_request(endpoint)\n",
    "        # Log the response status code and rate limit headers\n",
    "        logging.info(f\"Successfully retrieved song chars for chartmetric id {chartmetric_id}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to get song chars for chartmetric id {chartmetric_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Extract the song characteristics from the response\n",
    "    song_chars = response\n",
    "\n",
    "    return song_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15447513.0\n"
     ]
    }
   ],
   "source": [
    "pprint(chartmetric_ids_spotify[\"chartmetric_ids\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial run with a single ID \n",
    "\n",
    "search_output = get_songchars_ids(chartmetric_ids_spotify[\"chartmetric_ids\"][0])\n",
    "\n",
    "\n",
    "pprint(search_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial the function with the search output\n",
    "\n",
    "test_df = extract_song_info(search_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_data_chartmetric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
